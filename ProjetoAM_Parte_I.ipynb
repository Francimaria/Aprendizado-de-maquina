{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjetoAM - Parte I.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSW-eewFBexP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import math as mt\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.optimize import linear_sum_assignment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vor8PuR-eL2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SMALL_VALUE = 1e-18"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHkkM_gpnCFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adequacyCriterion(K,p,m,s,Lambda,D,U,G):\n",
        "  result = []  \n",
        "  for k in range(K):\n",
        "    somaU = np.power(U[:,[k]],m).sum()   \n",
        "    lam = 0\n",
        "    auxL = []\n",
        "    for j in range(p):    \n",
        "      dist = []  \n",
        "      lam = (np.power(Lambda[k][j],s))\n",
        "      dj = np.matrix(D[j])\n",
        "      for q in range(len(G[0])):\n",
        "        e_ = G[k][q]\n",
        "        dist.append(dj[:,[e_]].sum())\n",
        "      auxL.append(lam*sum(dist))\n",
        "    soma = sum(auxL)\n",
        "    result.append(somaU * soma)\n",
        "  return sum(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRjCo7CqNNnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _members(K,n,p,Lambda,D,G,m=1.6):\n",
        "\ts = 1.0\n",
        "\tU = np.zeros((n, K), dtype=float)\n",
        "\tfor i in range(n):\n",
        "\t\tfor k in range(K):\n",
        "\t\t\tsoma_tmp = []\n",
        "\t\t\tfor h in range(K):\n",
        "\t\t\t\tdist_gk = []\n",
        "\t\t\t\tdist_gh = []\n",
        "\t\t\t\tfor j in range(p):\n",
        "\t\t\t\t\tfor q in range(len(G[0])):\n",
        "\t\t\t\t\t\tdist_gk.append(D[j][i][G[k][q]])\n",
        "\t\t\t\t\t\tdist_gh.append(D[j][i][G[h][q]])\n",
        "\t\t\t\tparte1 = sum((Lambda[k,:])**s) * sum(dist_gk)\n",
        "\t\t\t\tparte2 = sum((Lambda[h,:])**s) * sum(dist_gh)\n",
        "\t\t\t\tif parte1 == 0.0:\n",
        "\t\t\t\t\tparte1 = SMALL_VALUE\n",
        "\t\t\t\tif parte2 == 0.0:\n",
        "\t\t\t\t\tparte2 = SMALL_VALUE\t\n",
        "\t\t\t\ttmp = (parte1/parte2) ** (2/(m-1))\n",
        "\t\t\t\tsoma_tmp.append(tmp)\t\n",
        "\t\t\tresult = (sum(soma_tmp))**(-1)\n",
        "\t\t\tU[i][k] = result\n",
        "\treturn U"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GELCzt8l2mO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prototypes(n, K, Lambda, m, s, q, D, U, p):\n",
        "    l = []\n",
        "    lp = []\n",
        "    for i in range(n):\n",
        "        lk = []\n",
        "        for k in range(K):\n",
        "            sumLD = 0\n",
        "            sumU = (U[i][k])**m\n",
        "            for P in range(p):\n",
        "                mult = (Lambda[k][P]**s)*sum(D[P][i])\n",
        "                sumLD+=mult\n",
        "            lk.append(sumU*sumLD)\n",
        "        lp.append(lk)\n",
        "        aux = np.array(lp)\n",
        "        l = aux.argsort(axis=0)\n",
        "\n",
        "    aux = []\n",
        "    g = []\n",
        "    for Q in range(q):\n",
        "        for x in range(K):\n",
        "            if (l[Q][x] not in aux and l[Q][x] != -1):\n",
        "                aux.append(l[Q][x])\n",
        "                if(l[Q][x] == -1):\n",
        "                    aux.append(l[Q+1][x])\n",
        "                l[Q][x] = -1\n",
        "            else:\n",
        "                control = 0\n",
        "                while (control == 0):\n",
        "                    Q = Q + 1\n",
        "                    if (l[Q][x] not in aux and l[Q][x] != -1):\n",
        "                        aux.append(l[Q][x])\n",
        "                        if (l[Q][x] == -1):\n",
        "                            aux.append(l[Q + 1][x])\n",
        "                        l[Q][x] = -1\n",
        "                        control = 1\n",
        "            Q = 0\n",
        "        g.append(aux)\n",
        "        aux=[]\n",
        "    G = np.transpose(g)\n",
        "    return G"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2AI6-lyBu2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lambda_K(n, K, m, q, D, U, p, G):\n",
        "  lambda_kj = []\n",
        "  l = []\n",
        "  part1 = 1\n",
        "  gk = 0\n",
        "  for k in range(K):\n",
        "    sumU = 0\n",
        "    #Somatório de todos os exemplos Ui de cada K\n",
        "    for i in range(n):\n",
        "      sumU += U[i][k] ** m\n",
        "    #Somatório de todos os exemplos Ei da matriz de Dj em relação ao exemplo do grupo Gk  \n",
        "    vetD = []\n",
        "    sumD = []\n",
        "    prod = []\n",
        "    \n",
        "    for d in range (p):\n",
        "      #Pega o representante do grupo Gk\n",
        "      gk = G[k]\n",
        "      #Soma todos os exemplos Ei da matriz j em relação ao exemplo gk                                                  \n",
        "      vetD.append(sum(D[d][gk][0:len(D[d])]))\n",
        "\n",
        "    for v in vetD:\n",
        "      sumD.append (sum(v))             \n",
        "      \n",
        "    #Função para calcular o produto de Ui com o somatório de cada matriz\n",
        "    for value in sumD:\n",
        "      prod.append(sumU * value)\n",
        "    #Variável que calcula o produtório entre todos os produtos\n",
        "    part1 = np.product(prod)**(1/p)\n",
        "\n",
        "    #Função que realiza a divisão entre o produtório e os produtos individuais de cada matriz\n",
        "    res = []\n",
        "    count = 0\n",
        "    for pdt in prod:\n",
        "      res.append(part1/pdt)\n",
        "      count +=1\n",
        "    l.append(res)\n",
        "  lambda_kj = np.reshape(l, (K, p))\n",
        "  return lambda_kj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCpL2SjiDPDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PartEntropy(U, n, K):\n",
        "  PE = 0\n",
        "  for k in range (K):\n",
        "    for i in range (n):\n",
        "      PE += (U[i][k]) * (mt.log(U[i][k])/n)\n",
        "  return -PE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8djEkfgDafZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PartCoef(U, n, K):\n",
        "  PC = 0\n",
        "  for k in range (K):\n",
        "    for i in range (n):\n",
        "      PC += (U[i][k])**2 /n\n",
        "  return PC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1owf7cJDgfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ModPartCoef(U, n, K):\n",
        "  MPC = 1 - K/(K-1)*(1-PartCoef(U, n, K))\n",
        "  return MPC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb90JMRKs41A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cluster_acc(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate clustering accuracy. Require from scipy.optimize import linear_sum_assignment\n",
        "    # Arguments\n",
        "        y: true labels, numpy.array with shape `(n_samples,)`\n",
        "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
        "    # Return\n",
        "        accuracy, in [0,1]\n",
        "    \"\"\"\n",
        "    y_true = y_true.astype(np.int64)\n",
        "    assert y_pred.size == y_true.size\n",
        "    D = max(y_pred.max(), y_true.max()) + 1\n",
        "    w = np.zeros((D, D), dtype=np.int64)\n",
        "    for i in range(y_pred.size):\n",
        "        w[y_pred[i], y_true[i]] += 1\n",
        "    ind = linear_sum_assignment(w.max() - w)\n",
        "    ind = np.asarray(ind)\n",
        "    ind = np.transpose(ind)\n",
        "    return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuZ9M1avBq6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MFCMddRWL(D,K=10,q=1, max_t=150, m=1.6, error=(10**(-10))):\n",
        "\t\"\"\"\n",
        "\tO algoritmo recebe os seguintes parâmetros:\n",
        "\tD - matriz de dissimilaridade \n",
        "\tK - número de clusters (default= 10)\n",
        "\tq - cardinalidade de G_k (default=1)\n",
        "\tt - total de iterações (default=150)\n",
        "\tm - ...\t\t\t\t\t(default=1.6)\n",
        "\terror - que é o error  (default =1e-10) \n",
        "\t\"\"\"\n",
        "\n",
        "\t\"\"\"\n",
        "\tINICIALIZAÇÃO \n",
        "\t\"\"\"\n",
        "\t#cardinalidade q de G_k\n",
        "\t\n",
        "\tt = 0\n",
        "\ts = 1.0\n",
        "\n",
        "\t#quantidade de matrizes\n",
        "\tp = len(D)\n",
        "\tn = len(D[0])\n",
        "\n",
        "\t#MFCMddRWL-P - Matching function 7 -  o produto dos pesos é igual a 1\n",
        "\t#matriz de pesos relevantes Lambda_kp\n",
        "\tLambda = np.array([[1 for pp in range(p)] for k in range(K)])\n",
        "\n",
        "\t#vetor de protótipos \n",
        "\t#G = np.random.choice(n, size=K,replace=False)\t\n",
        "\tG = np.random.choice(n,[K,q],replace=False)\n",
        "\n",
        "\t#inicialização da matriz U\n",
        "\tU = _members(K,n,p,Lambda,D,G,m)\n",
        " \n",
        "\t# calcule o critério de adequação J⁽⁰⁾\n",
        "\tJ = adequacyCriterion(K,p,m,s,Lambda,D,U,G)\n",
        "\tJold = 0\n",
        "\n",
        "\tcount = 0\n",
        "\n",
        "\twhile((abs(J - Jold) >= error) and (t < max_t)):\n",
        "\t\t#(2) Step 1: Calculo dos melhores protótipos\n",
        "\n",
        "\t\tt = t + 1\n",
        "\n",
        "\t\t# U e Lambda são fixados\n",
        "\t\t#Calculando Gk = G* e E^(q)\n",
        "\t\tG = prototypes(n, K, Lambda, m, s, q, D, U, p)\n",
        "\t\t\n",
        "\t\t# (3) Step 2: computando a melhor matriz de pesos relevantes \n",
        "\t\t#matriz de pesos relevantes Lambda_kp\n",
        "\t\t#U^(t-1) e G são fixados \n",
        "\t\tLambda = lambda_K(n, K, m, q, D, U, p, G)\n",
        "\t\t\t\t\t\t \n",
        "\t\t# (4) Step 3: definição da melhor partição fuzzy\n",
        "\t\t# o vetor G e Lambda são fixos \n",
        "\t\tU = _members(K,n,p,Lambda,D,G,m)\n",
        "\t\t \n",
        "\t\t# critério de parada \n",
        "\t\t# calcule o critério de adequação J^(t) e Jold = J(t - 1)\n",
        "\t\tJold = J\n",
        "\t\tJ = adequacyCriterion(K,p,m,s,Lambda,D,U,G)\n",
        "\treturn G, U, J"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5Hdd2rIBZwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "\t#dataset\n",
        "\tview1 = pd.read_csv('https://raw.githubusercontent.com/Francimaria/Machine-Learning-Python/master/mfeat-fac.csv', header=None, delim_whitespace=True)\n",
        "\tview2 = pd.read_csv('https://raw.githubusercontent.com/Francimaria/Machine-Learning-Python/master/mfeat-fou.csv', header=None, delim_whitespace=True)\n",
        "\tview3 = pd.read_csv('https://raw.githubusercontent.com/Francimaria/Machine-Learning-Python/master/mfeat-kar.csv', header=None, delim_whitespace=True)\n",
        "\n",
        "\t#normalização\n",
        "\t# max \n",
        "\tview1 = preprocessing.normalize(view1,'max')\n",
        "\tview2 = preprocessing.normalize(view2,'max')\n",
        "\tview3 = preprocessing.normalize(view3,'max')\n",
        " \n",
        "\n",
        "\t#Euclidian distance \n",
        "\t# Cada matriz tem o tamanho nxn (2000x2000)\n",
        "\tD1 = euclidean_distances(view1,view1)\n",
        "\tD2 = euclidean_distances(view2, view2)\n",
        "\tD3 = euclidean_distances(view3,view3)\n",
        " \n",
        " \n",
        "\t#D é composto pelas 3 matrizes de dissimilaridade \n",
        "\t#Assim D é um vetor de p matrizes \n",
        "\tD = [D1,D2,D3]\n",
        "\n",
        "\t#função\n",
        "\t#rodar 100 vezes para obter uma partição fuzzy em 10 grupos\n",
        "\tprototypes = []\n",
        "\tmembers = []\n",
        "\tobjective = []\n",
        "\tfor i in range(100):\n",
        "\t\tprint(i)\n",
        "\t\tG, U, J = MFCMddRWL(D,K=10,q=2)\n",
        "\t\tprototypes.append(G)\n",
        "\t\tmembers.append(U)\n",
        "\t\tobjective.append(J)\n",
        "\t# index da função objetivo com menor valor\n",
        "\tindex_array = np.argmin(objective, axis=-1)\n",
        "\tG = prototypes[index_array]\n",
        "\tU = members[index_array]\n",
        "\tJ = objective[index_array]\n",
        "\n",
        "\t# Salve em csv as matrizes\n",
        "\tnp.savetxt(\"/content/sample_data/G_tres_matrizes.csv\",G.astype(int), fmt='%i',delimiter=\",\")\n",
        "\tnp.savetxt(\"/content/sample_data/U_tres_matrizes.csv\",U,delimiter=\",\")\n",
        "\n",
        "\tK = 10\n",
        "\tn = len(D[0])\n",
        "\n",
        "  #partição CRISP\n",
        "\tcluster_membership = np.argmax(U, axis=1) \n",
        "\tgrupos  = [[i for i in range(len(cluster_membership)) if k == cluster_membership[i]] for k in range(K) ]\n",
        "\t#mostra a quantidade de elementos em cada grupo e o índice dos elementos de cada grupo\n",
        "\tprint(\"** DESCRIÇÃO DOS GRUPOS **\")\n",
        "\tprint(\"SET-MEDOIDS (protótipo)\")\n",
        "\tprint(G)\n",
        "\tprint(\"PARTIÇÃO CRISP E A QUANTIDADE DE OBJETOS\")\n",
        "\tprint(\"_________________________________________________________\")\n",
        "\tfor k in range(K):\n",
        "\t\tprint(\"GRUPO\", k+1,\":\",len(grupos[k]))\n",
        "\t\tprint(\"Obj:\", (grupos[k]))\n",
        "\t\tprint(\"_________________________________________________________\")\n",
        "\t\n",
        "\t# Salve em csv as labels da partição crisp\n",
        "\tnp.savetxt(\"/content/sample_data/cluster_membership_tres_m.csv\",cluster_membership.astype(int), fmt='%i', delimiter=\",\")\n",
        "\t\n",
        "\t#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html\n",
        "\t#índice de Rand corrigido adjusted_rand_score(labels_true, labels_pred)\t\n",
        "\t#The first 200 patterns are of class `0', followed by sets of 200 patterns for each of the classes `1' - `9'.\n",
        "\t\n",
        "\tlabels_= [i for i in range(10) for _ in range(200)]\n",
        "\ty_true = np.asarray(labels_, dtype=np.int64)\n",
        "\n",
        "\trc = adjusted_rand_score(labels_, cluster_membership)\n",
        "\tprint(\"Índice de rand corrigido: \", rc)\n",
        " \n",
        "  #F-measure e erro de classificação (atribuição).\t\n",
        "\tf1_measure_macro = f1_score(labels_, cluster_membership, average='macro')\n",
        "\tprint(\"F-measure Macro: \",f1_measure_macro)\n",
        "\t\n",
        "\tf1_measure_micro = f1_score(labels_, cluster_membership, average='micro')\n",
        "\tprint(\"F-measure Micro: \", f1_measure_micro )\n",
        "\n",
        "\tf1_measure_ = f1_score(labels_, cluster_membership, average=None)\n",
        "\tprint(\"F-measure: \",f1_measure_)\n",
        "\n",
        "\t#acc = accuracy_score(labels_, cluster_membership) \n",
        "\t#print(\"Erro de classificação: \", (1-acc))\n",
        " \n",
        "\tc_acc = cluster_acc(y_true, cluster_membership)\n",
        "\tprint(\"Erro de Classificação do Cluster\", (1-c_acc))\n",
        " \n",
        " \t#Coeficientes\n",
        "\tPE = PartEntropy(U, n, K)\n",
        "\tprint(\"Partition Entropy:\", PE)\n",
        "\tMPC = ModPartCoef(U, n, K)\n",
        "\tprint(\"Modified Partition Coefficient:\", MPC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ydF88MLILUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}