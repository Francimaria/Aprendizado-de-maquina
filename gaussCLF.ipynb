{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gaussCLF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKuXQBoRPoY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from scipy.stats import multivariate_normal\n",
        "import math\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "from scipy.stats import sem, t\n",
        "from scipy import mean\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1HDJGfq2Pde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Based on: https://towardsdatascience.com/how-to-impliment-a-gaussian-naive-bayes-classifier-in-python-from-scratch-11e0b80faf5a\n",
        "class gaussClf:\n",
        "\n",
        "    _ALPHA_MIN = 1e-200\n",
        "    _ALPHA_MAX = 1e+200\n",
        "\n",
        "    def separate_by_classes(self, X, y):\n",
        "        ''' Essa função separa o conjunto de dados em sub-conjuntos por classe '''\n",
        "        self.classes = np.unique(y)\n",
        "        classes_index = {}\n",
        "        subdatasets = {}\n",
        "        cls, counts = np.unique(y, return_counts=True)\n",
        "        self.class_freq = dict(zip(cls, counts))\n",
        "        for class_type in self.classes:\n",
        "            classes_index[class_type] = np.argwhere(y==class_type)\n",
        "            subdatasets[class_type] = X[classes_index[class_type], :]\n",
        "            self.class_freq[class_type] = self.class_freq[class_type]/sum(list(self.class_freq.values()))\n",
        "        return subdatasets\n",
        "        \n",
        "    def meanCov(self,X,y):\n",
        "      separated_X = self.separate_by_classes(X, y)\n",
        "      mean_c = {}\n",
        "      sigma_c = {}\n",
        "      for class_type in self.classes:\n",
        "          # Aqui calculamos a média e a matriz Sigma diagonal\n",
        "          Xc = np.asmatrix(separated_X[class_type])\n",
        "          mean_c[class_type] = np.asarray(np.mean(Xc, axis=0))[0]\n",
        "          cov_c = np.zeros((Xc.shape[1], Xc.shape[1]))\n",
        "          for j in range(Xc.shape[1]):\n",
        "            var = np.var(Xc[:,[j]].reshape((1,Xc.shape[0])))\n",
        "            cov_c[j][j] = var          \n",
        "          sigma_c[class_type] = cov_c\n",
        "      return mean_c, sigma_c\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        ''' Funçãão fit para cada uma das 3 views'''\n",
        "        self.meansView1, self.sigmaView1 = self.meanCov(X[0],y)\n",
        "        self.meansView2, self.sigmaView2 = self.meanCov(X[1],y)\n",
        "        self.meansView3, self.sigmaView3 = self.meanCov(X[2],y)\n",
        "\n",
        "    def calculate_probability(self, x, mean, sigmad):   \n",
        "      normal_mult = multivariate_normal.pdf(x,mean=mean,cov=sigmad,allow_singular=True)\n",
        "      return normal_mult\n",
        "\n",
        "    def testeP(self, x):\n",
        "      if x > self._ALPHA_MAX:\n",
        "        return self._ALPHA_MAX\n",
        "      if x == 0.0:\n",
        "        return self._ALPHA_MIN\n",
        "      return x\n",
        "\n",
        "    def predict_proba_soma(self, X):\n",
        "      #número de view\n",
        "        L = len(X)\n",
        "        view1 = X[0]\n",
        "        view2 = X[1]\n",
        "        view3 = X[2]\n",
        "        #colunas\n",
        "        ''' Prediz a probabilidade para todas as classes log-verossimilhança'''\n",
        "        self.class_prob = {cls:((1-L)*math.log(self.class_freq[cls], math.e)) for cls in self.classes}  \n",
        "\n",
        "        for cls in self.classes:   \n",
        "            pView1 = self.testeP(self.calculate_probability(view1, self.meansView1[cls], self.sigmaView1[cls]))\n",
        "            pView2 = self.testeP(self.calculate_probability(view2, self.meansView2[cls], self.sigmaView2[cls]))\n",
        "            pView3 = self.testeP(self.calculate_probability(view3, self.meansView3[cls], self.sigmaView3[cls]))\n",
        "            self.class_prob[cls]+=((math.log(pView1,math.e)) + (math.log(pView2,math.e)) + (math.log(pView3,math.e)))\n",
        "        self.class_prob = {cls: math.e**self.class_prob[cls] for cls in self.class_prob}\n",
        "        return self.class_prob\n",
        "\n",
        "    def predict(self, X):\n",
        "        ''' Essa função prediz a probabilidade da classe de uma amostra '''\n",
        "        pred = []\n",
        "        v1 = X[0]\n",
        "        v2 = X[1]\n",
        "        v3 = X[2]\n",
        "        for i in range(len(X[0])):\n",
        "            pred_class = None\n",
        "            max_prob = 0\n",
        "            x =[v1[i],v2[i],v3[i]]\n",
        "            for cls, prob in self.predict_proba_soma(x).items():\n",
        "                if prob>max_prob:\n",
        "                    max_prob = prob\n",
        "                    pred_class = cls\n",
        "            pred.append(pred_class)\n",
        "        return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZvCr_yBP87v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataset\n",
        "view1 = pd.read_csv('https://raw.githubusercontent.com/Francimaria/Machine-Learning-Python/master/mfeat-fac.csv', header=None, delim_whitespace=True)\n",
        "view2 = pd.read_csv('https://raw.githubusercontent.com/Francimaria/Machine-Learning-Python/master/mfeat-fou.csv', header=None, delim_whitespace=True)\n",
        "view3 = pd.read_csv('https://raw.githubusercontent.com/Francimaria/Machine-Learning-Python/master/mfeat-kar.csv', header=None, delim_whitespace=True)\n",
        "\n",
        "#normalização\n",
        "view1 = preprocessing.normalize(view1,'max')\n",
        "view2 = preprocessing.normalize(view2,'max')\n",
        "view3 = preprocessing.normalize(view3,'max')\n",
        "\n",
        "#classes\n",
        "classes = pd.read_csv('https://raw.githubusercontent.com/Francimaria/Machine-Learning-Python/master/cluster_membership_tres_m.csv', header=None, delim_whitespace=True)\n",
        "\n",
        "y = np.array(classes.values).T[0]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skAbAXR4Q9LQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rkf = RepeatedStratifiedKFold(n_splits=10, n_repeats=30)\n",
        "\n",
        "scores = []\n",
        "\n",
        "bg = gaussClf()\n",
        "\n",
        "for train_index, test_index in rkf.split(view1,y):\n",
        "  v1_train, v1_test = view1[train_index], view1[test_index]\n",
        "  v2_train, v2_test = view2[train_index], view2[test_index]\n",
        "  v3_train, v3_test = view3[train_index], view3[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "  X_train = [v1_train,v2_train,v3_train]\n",
        "  X_test = [v1_test,v2_test,v3_test]\n",
        "\n",
        "  bg.fit(X_train,y_train)\n",
        "\n",
        "  y_pred = bg.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  scores.append(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_ZTnX6dAJ8o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "028e3364-e9f7-4cb2-d6d0-85a95a60b0a3"
      },
      "source": [
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.715, 0.68, 0.64, 0.67, 0.675, 0.725, 0.705, 0.71, 0.69, 0.7, 0.705, 0.71, 0.735, 0.68, 0.72, 0.655, 0.67, 0.695, 0.66, 0.7, 0.675, 0.685, 0.73, 0.705, 0.655, 0.695, 0.65, 0.685, 0.7, 0.715, 0.615, 0.68, 0.66, 0.7, 0.72, 0.72, 0.65, 0.69, 0.74, 0.745, 0.695, 0.635, 0.655, 0.68, 0.73, 0.685, 0.7, 0.705, 0.72, 0.705, 0.685, 0.705, 0.685, 0.69, 0.695, 0.685, 0.66, 0.67, 0.675, 0.73, 0.69, 0.735, 0.715, 0.67, 0.685, 0.66, 0.685, 0.69, 0.715, 0.67, 0.71, 0.64, 0.67, 0.725, 0.735, 0.7, 0.695, 0.62, 0.685, 0.715, 0.725, 0.675, 0.725, 0.675, 0.69, 0.71, 0.685, 0.685, 0.7, 0.675, 0.67, 0.7, 0.705, 0.68, 0.645, 0.665, 0.73, 0.715, 0.715, 0.65, 0.705, 0.645, 0.69, 0.7, 0.645, 0.66, 0.645, 0.735, 0.73, 0.735, 0.69, 0.665, 0.7, 0.715, 0.685, 0.71, 0.695, 0.705, 0.69, 0.66, 0.685, 0.7, 0.735, 0.675, 0.645, 0.72, 0.675, 0.71, 0.68, 0.685, 0.695, 0.73, 0.695, 0.76, 0.665, 0.725, 0.68, 0.69, 0.64, 0.635, 0.655, 0.655, 0.705, 0.71, 0.74, 0.695, 0.685, 0.695, 0.695, 0.655, 0.645, 0.675, 0.71, 0.67, 0.735, 0.74, 0.725, 0.69, 0.69, 0.685, 0.645, 0.745, 0.725, 0.75, 0.69, 0.64, 0.69, 0.655, 0.715, 0.71, 0.645, 0.69, 0.65, 0.71, 0.68, 0.665, 0.695, 0.735, 0.77, 0.635, 0.67, 0.695, 0.685, 0.725, 0.72, 0.685, 0.665, 0.685, 0.71, 0.685, 0.755, 0.665, 0.63, 0.715, 0.675, 0.685, 0.69, 0.705, 0.66, 0.72, 0.765, 0.705, 0.73, 0.685, 0.64, 0.7, 0.65, 0.685, 0.645, 0.72, 0.75, 0.675, 0.665, 0.65, 0.725, 0.695, 0.7, 0.645, 0.7, 0.675, 0.675, 0.735, 0.71, 0.675, 0.67, 0.69, 0.665, 0.675, 0.72, 0.725, 0.735, 0.67, 0.7, 0.675, 0.67, 0.61, 0.715, 0.695, 0.71, 0.715, 0.68, 0.695, 0.71, 0.69, 0.73, 0.67, 0.76, 0.645, 0.715, 0.64, 0.695, 0.74, 0.715, 0.67, 0.67, 0.655, 0.655, 0.665, 0.735, 0.69, 0.725, 0.675, 0.73, 0.65, 0.695, 0.64, 0.7, 0.71, 0.7, 0.67, 0.675, 0.66, 0.71, 0.615, 0.7, 0.705, 0.75, 0.69, 0.68, 0.73, 0.615, 0.705, 0.7, 0.715, 0.77, 0.71, 0.655, 0.695, 0.665, 0.68, 0.685, 0.685, 0.695, 0.695, 0.705, 0.68, 0.695, 0.67, 0.735, 0.64]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfPH5rzVpImh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8b6122a7-4442-4448-dd36-914bd584e08d"
      },
      "source": [
        "confidence = 0.95\n",
        "\n",
        "n = len(scores)\n",
        "m = mean(scores)\n",
        "\n",
        "std_ = np.std(scores)\n",
        "std_err = sem(scores)\n",
        "\n",
        "h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
        "\n",
        "print (\"Média - \",m)\n",
        "print (\"desvio padrão - \", std_)\n",
        "print(\"Erro padrão - \", std_err)\n",
        "\n",
        "start = m - h\n",
        "end = m + h\n",
        "print(\"Intervalo de confiança -\", start, \" - \", end)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média -  0.6909833333333334\n",
            "desvio padrão -  0.030308685040576863\n",
            "Erro padrão -  0.001752796512722741\n",
            "Intervalo de confiança - 0.687533953072112  -  0.6944327135945548\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}