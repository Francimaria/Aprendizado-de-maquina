{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BayesParzen.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmETcpVxIGJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.stats import sem, t\n",
        "from scipy import mean\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJJ4xPQxl6mn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BayesParzen:\n",
        "\n",
        "  def __init__(self, h = 0.1):\n",
        "    self.h = h\n",
        "\n",
        "  def get_params(self, deep=True):\n",
        "    return {\"h\": self.h}\n",
        "\n",
        "  def set_params(self, **parameters):\n",
        "    for parameter, value in parameters.items():\n",
        "        setattr(self, parameter, value)\n",
        "    return self\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    n_samples, n_features = X.shape\n",
        "    self._classes = np.unique(y)\n",
        "    n_classes = len(self._classes)\n",
        "    self.n = n_samples\n",
        "\n",
        "    # calcula a média, variância e a prior de cada classe\n",
        "    self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
        "    self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
        "    self._priors =  np.zeros(n_classes, dtype=np.float64)\n",
        "\n",
        "    for idx, c in enumerate(self._classes):\n",
        "      X_c = X[y==c]\n",
        "      self._mean[idx, :] = X_c.mean(axis=0)\n",
        "      self._var[idx, :] = X_c.var(axis=0)\n",
        "      self._priors[idx] = X_c.shape[0] / float(n_samples)\n",
        "\n",
        "  def predict(self, X):\n",
        "    y_pred = [self._predict(x) for x in X]\n",
        "    return np.array(y_pred)\n",
        "\n",
        "  def _predict(self, x):\n",
        "    posteriors = []\n",
        "    #Calcula a probabilidade posterior de cada class\n",
        "    for idx, c in enumerate(self._classes):\n",
        "      prior = np.log(self._priors[idx])\n",
        "      posterior = prior + (np.log(self.multivariatePDF(idx, x)))\n",
        "      posteriors.append(posterior)\n",
        "      \n",
        "    # retorna a maior probabilidade a posteriori\n",
        "    return np.argmax(posteriors)\n",
        "\n",
        "  # Função de kernel multivariada       \n",
        "  def multivariatePDF(self, class_idx, x):\n",
        "    p = (1/self.n) * (1/h) *  np.sum(np.prod(self.gaussian1D(class_idx, x)))\n",
        "    return p\n",
        "  \n",
        "  def gaussian1D(self, class_idx, x):\n",
        "    mean = self._mean[class_idx]\n",
        "    var = self._var[class_idx]\n",
        "    g1d = 1/np.sqrt(2 * np.pi * var) * np.exp(-(x - mean)**2/(2 * var))\n",
        "    return g1d\n",
        "\n",
        "  def predictProba(self, X):\n",
        "    prob = [self._predictProba(x) for x in X]\n",
        "    return np.array(prob)\n",
        "\n",
        "  def _predictProba(self, x):\n",
        "      posteriors = []\n",
        "\n",
        "       #Calcula a probabilidade posterior de cada class\n",
        "      for idx, c in enumerate(self._classes):\n",
        "        prior = np.log(self._priors[idx])\n",
        "        posterior = prior + (np.log(self.multivariatePDF(idx, x)))\n",
        "        posteriors.append(posterior)\n",
        "\n",
        "      # retorna as probabilidades a posteriori\n",
        "      return posteriors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DEAeHSJHjT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "view1 = pd.read_csv(r'https://raw.githubusercontent.com/jsaj/MachineLearning/master/mfeat-fac.csv',header=None, delim_whitespace=True)\n",
        "view1 = preprocessing.normalize(view1, 'max')\n",
        "\n",
        "view2 = pd.read_csv(r'https://raw.githubusercontent.com/jsaj/MachineLearning/master/mfeat-fou.csv',header=None, delim_whitespace=True)\n",
        "view2 = preprocessing.normalize(view2, 'max')\n",
        "\n",
        "view3 = pd.read_csv(r'https://raw.githubusercontent.com/jsaj/MachineLearning/master/mfeat-kar.csv',header=None, delim_whitespace=True)\n",
        "view3 = preprocessing.normalize(view3, 'max')\n",
        "\n",
        "target = pd.read_csv(r'https://raw.githubusercontent.com/jsaj/MachineLearning/master/cluster_membership_tres_m.csv',header=None, delim_whitespace=True)\n",
        "\n",
        "X1 = view1\n",
        "X2 = view2\n",
        "X3 = view3\n",
        "\n",
        "y = target[target.columns[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vkOVAQ3OEvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictSoma(pred, X_test1, y_test):\n",
        "    soma = []\n",
        "    p = []\n",
        "    sum = 0\n",
        "    y_pred = []\n",
        "    _classes = np.unique(y)\n",
        "    priors = []\n",
        "    for x in range (len(X_test1)):\n",
        "      for idx, c in enumerate(_classes):\n",
        "          nj = np.count_nonzero(y_test == idx)\n",
        "          priori = nj/len(y_test)\n",
        "          priors.append(priori)\n",
        "          for clf in range(3):\n",
        "            sum = sum + pred[x][clf][idx]\n",
        "          soma.append(sum)\n",
        "          sum = 0\n",
        "          aux = ((1-3)*priors[idx] + soma[idx])\n",
        "          p.append(aux)\n",
        "      soma=[]\n",
        "      y_pred.append(np.argmax(p))\n",
        "      p=[]\n",
        "    return np.array(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwkvPSevmdtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=30)\n",
        "scores = []\n",
        "for train_index, test_index in rskf.split(X1,y):\n",
        "    X_train1, X_test1 = X1[train_index], X1[test_index]\n",
        "    X_train2, X_test2 = X2[train_index], X2[test_index]\n",
        "    X_train3, X_test3 = X3[train_index], X3[test_index]\n",
        "    \n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    X_val1,X_valt1,y_val1,y_valt1 = train_test_split(X_train1, y_train,train_size=0.20)\n",
        "    X_val2,X_valt2,y_val2,y_valt2 = train_test_split(X_train2, y_train,train_size=0.20)\n",
        "    X_val3,X_valt3,y_val3,y_valt3 = train_test_split(X_train3, y_train,train_size=0.20)\n",
        "\n",
        "    Xval = [X_val1, X_val2, X_val3]\n",
        "    yval = [y_val1, y_val2, y_val3]\n",
        "\n",
        "    bandwidths = np.linspace(0.1, 1, 10)\n",
        "    H = []\n",
        "    for i in range(len(Xval)):\n",
        "      for h in bandwidths:\n",
        "        nb = BayesParzen(h = h)\n",
        "        scor = cross_val_score(nb, Xval[i], yval[i], cv=10, scoring='accuracy')\n",
        "\n",
        "      mse = [1 - x for x in scor]\n",
        "      # determina o melhor h\n",
        "      optimal_h = bandwidths[mse.index(min(mse))] \n",
        "      H.append(optimal_h)\n",
        "    \n",
        "    model1 = BayesParzen(H[0])\n",
        "    model2 = BayesParzen(H[1])\n",
        "    model3 = BayesParzen(H[2])\n",
        "\n",
        "    model1.fit (X_train1, y_train) \n",
        "    model2.fit (X_train2, y_train) \n",
        "    model3.fit (X_train3, y_train) \n",
        "\n",
        "    pred1 = model1.predictProba(X_test1)\n",
        "    pred2 = model2.predictProba(X_test2) \n",
        "    pred3 = model3.predictProba(X_test3)\n",
        "    pred = [[pred1[x], pred2[x], pred3[x]]  for x in range (len(X_test1))]\n",
        "    \n",
        "    y_pred = predictSoma(pred, X_test1, y_test)\n",
        "    score = accuracy_score(y_test, y_pred)\n",
        "    scores.append(score)\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObLNHgZu8iA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bd8910a8-4fb7-4a2d-97df-869d1be68058"
      },
      "source": [
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.66, 0.66, 0.695, 0.705, 0.725, 0.7, 0.735, 0.65, 0.725, 0.685, 0.7, 0.685, 0.72, 0.63, 0.71, 0.695, 0.72, 0.72, 0.725, 0.67, 0.695, 0.68, 0.725, 0.705, 0.73, 0.665, 0.675, 0.695, 0.675, 0.725, 0.69, 0.71, 0.7, 0.675, 0.775, 0.65, 0.715, 0.69, 0.705, 0.69, 0.655, 0.725, 0.715, 0.69, 0.67, 0.69, 0.715, 0.7, 0.705, 0.665, 0.76, 0.695, 0.69, 0.7, 0.675, 0.625, 0.705, 0.685, 0.72, 0.715, 0.72, 0.69, 0.745, 0.68, 0.67, 0.715, 0.715, 0.63, 0.66, 0.735, 0.74, 0.71, 0.645, 0.645, 0.7, 0.72, 0.715, 0.705, 0.71, 0.69, 0.72, 0.725, 0.675, 0.67, 0.705, 0.685, 0.64, 0.745, 0.655, 0.77, 0.715, 0.695, 0.7, 0.675, 0.67, 0.71, 0.695, 0.66, 0.705, 0.765, 0.66, 0.695, 0.735, 0.72, 0.71, 0.69, 0.66, 0.695, 0.705, 0.71, 0.68, 0.695, 0.75, 0.655, 0.65, 0.73, 0.715, 0.72, 0.695, 0.69, 0.75, 0.705, 0.725, 0.625, 0.675, 0.705, 0.675, 0.71, 0.705, 0.71, 0.7, 0.7, 0.7, 0.72, 0.64, 0.735, 0.685, 0.63, 0.745, 0.7, 0.705, 0.63, 0.675, 0.715, 0.715, 0.74, 0.69, 0.71, 0.73, 0.655, 0.735, 0.695, 0.71, 0.685, 0.675, 0.705, 0.68, 0.685, 0.675, 0.705, 0.71, 0.725, 0.73, 0.625, 0.645, 0.7, 0.665, 0.69, 0.73, 0.735, 0.735, 0.735, 0.705, 0.705, 0.63, 0.665, 0.665, 0.75, 0.71, 0.67, 0.67, 0.685, 0.63, 0.69, 0.74, 0.67, 0.69, 0.745, 0.715, 0.715, 0.7, 0.7, 0.665, 0.71, 0.655, 0.74, 0.705, 0.675, 0.68, 0.73, 0.7, 0.68, 0.705, 0.695, 0.715, 0.65, 0.65, 0.69, 0.75, 0.74, 0.665, 0.725, 0.74, 0.67, 0.65, 0.69, 0.715, 0.665, 0.72, 0.715, 0.755, 0.68, 0.69, 0.69, 0.72, 0.665, 0.725, 0.635, 0.69, 0.72, 0.7, 0.645, 0.685, 0.715, 0.69, 0.71, 0.73, 0.69, 0.685, 0.72, 0.685, 0.725, 0.67, 0.715, 0.645, 0.67, 0.715, 0.725, 0.685, 0.685, 0.655, 0.67, 0.725, 0.71, 0.675, 0.64, 0.725, 0.72, 0.695, 0.71, 0.72, 0.7, 0.69, 0.7, 0.705, 0.62, 0.68, 0.72, 0.685, 0.75, 0.69, 0.71, 0.71, 0.775, 0.66, 0.69, 0.695, 0.675, 0.715, 0.685, 0.72, 0.715, 0.655, 0.68, 0.705, 0.7, 0.695, 0.725, 0.735, 0.68, 0.695, 0.725, 0.715, 0.66, 0.67, 0.73, 0.66, 0.68, 0.745, 0.725]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmkPYpL0gtol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "fcd3b1e3-3cf4-478b-cde8-ae0cb52e4c49"
      },
      "source": [
        "confidence = 0.95\n",
        "\n",
        "n = len(scores)\n",
        "m = mean(scores)\n",
        "\n",
        "std_ = np.std(scores)\n",
        "std_err = sem(scores)\n",
        "\n",
        "h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
        "\n",
        "print (\"Média - \",m)\n",
        "print (\"desvio padrão - \", std_)\n",
        "print(\"Erro padrão - \", std_err)\n",
        "\n",
        "start = m - h\n",
        "end = m + h\n",
        "print(\"Intervalo de confiança -\", start, \" - \", end)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média -  0.6968666666666666\n",
            "desvio padrão -  0.029933518930382284\n",
            "Erro padrão -  0.0017311000963734192\n",
            "Intervalo de confiança - 0.6934599834268915  -  0.7002733499064417\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}