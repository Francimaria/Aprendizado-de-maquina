{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOHgF2TYabF+0A3mqT3QeXU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import import_ipynb\n",
        "from autoencoder import Autoencoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95OY1_xLlO6K",
        "outputId": "88e3ca40-a1ea-45df-efa2-daeb7b9452c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from autoencoder.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "PW-qnf_qnU5E"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "BATCH_SIZE = 2\n",
        "EPOCHS = 20\n",
        "\n",
        "def load_mnist():\n",
        "  (x_train,y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "  #Apply normalization and add an extra dimension\n",
        "  x_train = x_train.astype(\"float32\") / 255 #put all samples between 0 and 1 \n",
        "  x_train = x_train.reshape(x_train.shape + (1,))\n",
        "\n",
        "  x_test = x_test.astype(\"float32\") / 255\n",
        "  x_test = x_test.reshape(x_test.shape + (1,))\n",
        "  \n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "metadata": {
        "id": "eZ82xWqZm_mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(x_train, learning_rate, batch_size, epochs):\n",
        "  autoencoder = Autoencoder(\n",
        "      input_shape=(28,28,1),\n",
        "      conv_filters=(32,64,64,64),\n",
        "      conv_kernels=(3,3,3,3),\n",
        "      conv_strides=(1,2,2,1),\n",
        "      latent_space_dim=2\n",
        "  )\n",
        "  autoencoder.summary()\n",
        "  autoencoder.compile(learning_rate)\n",
        "  autoencoder.train(x_train,batch_size, epochs)\n",
        "\n",
        "  return autoencoder"
      ],
      "metadata": {
        "id": "uPumCS4xoq1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "  x_train, _, _, _ = load_mnist()\n",
        "  autoencoder = train(x_train[:500], LEARNING_RATE, BATCH_SIZE, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RHA29lvmbOB",
        "outputId": "24eca0b2-d3db-460d-c3d5-70c44adfc705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_input (InputLayer)  [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " encoder_conv_layer_1 (Conv2  (None, 28, 28, 32)       320       \n",
            " D)                                                              \n",
            "                                                                 \n",
            " encoder_relu_1 (ReLU)       (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " encoder_bn_1 (BatchNormaliz  (None, 28, 28, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " encoder_conv_layer_2 (Conv2  (None, 14, 14, 64)       18496     \n",
            " D)                                                              \n",
            "                                                                 \n",
            " encoder_relu_2 (ReLU)       (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " encoder_bn_2 (BatchNormaliz  (None, 14, 14, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " encoder_conv_layer_3 (Conv2  (None, 7, 7, 64)         36928     \n",
            " D)                                                              \n",
            "                                                                 \n",
            " encoder_relu_3 (ReLU)       (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " encoder_bn_3 (BatchNormaliz  (None, 7, 7, 64)         256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " encoder_conv_layer_4 (Conv2  (None, 7, 7, 64)         36928     \n",
            " D)                                                              \n",
            "                                                                 \n",
            " encoder_relu_4 (ReLU)       (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " encoder_bn_4 (BatchNormaliz  (None, 7, 7, 64)         256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3136)              0         \n",
            "                                                                 \n",
            " encoder_output (Dense)      (None, 2)                 6274      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 99,842\n",
            "Trainable params: 99,394\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 2)]               0         \n",
            "                                                                 \n",
            " decoder_dense (Dense)       (None, 3136)              9408      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " decoder_conv_transpose_laye  (None, 7, 7, 64)         36928     \n",
            " r_1 (Conv2DTranspose)                                           \n",
            "                                                                 \n",
            " decoder_relu_1 (ReLU)       (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " decoder_bn_1 (BatchNormaliz  (None, 7, 7, 64)         256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " decoder_conv_transpose_laye  (None, 14, 14, 64)       36928     \n",
            " r_2 (Conv2DTranspose)                                           \n",
            "                                                                 \n",
            " decoder_relu_2 (ReLU)       (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " decoder_bn_2 (BatchNormaliz  (None, 14, 14, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " decoder_conv_transpose_laye  (None, 28, 28, 64)       36928     \n",
            " r_3 (Conv2DTranspose)                                           \n",
            "                                                                 \n",
            " decoder_relu_3 (ReLU)       (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " decoder_bn_3 (BatchNormaliz  (None, 28, 28, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " decoder_conv_transpose_laye  (None, 28, 28, 1)        577       \n",
            " r_4 (Conv2DTranspose)                                           \n",
            "                                                                 \n",
            " sigmoid_layer (Activation)  (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,537\n",
            "Trainable params: 121,153\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_input (InputLayer)  [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " encoder (Functional)        (None, 2)                 99842     \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 28, 28, 1)         121537    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 221,379\n",
            "Trainable params: 220,547\n",
            "Non-trainable params: 832\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "250/250 [==============================] - 6s 19ms/step - loss: 0.1032\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0789\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0748\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0695\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0646\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0626\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0608\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0596\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0572\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0560\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0544\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.0539\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0524\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0514\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0503\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0492\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0482\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0481\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0476\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.0470\n"
          ]
        }
      ]
    }
  ]
}