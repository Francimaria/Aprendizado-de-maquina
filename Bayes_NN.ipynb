{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayes-NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DApFBGRFKC1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from collections import Counter\n",
        "from sklearn import datasets\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.stats import sem, t\n",
        "from scipy import mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTz7mtgsptj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean_distance(x1, x2):\n",
        "    return np.sqrt(np.sum((x1 - x2)**2))\n",
        "\n",
        "class BayesNN:\n",
        "  def __init__(self, k=3):\n",
        "        self.k = k\n",
        "  \n",
        "  def get_params(self, deep=True):\n",
        "    return {\"k\": self.k}\n",
        "\n",
        "  def set_params(self, **parameters):\n",
        "    for parameter, value in parameters.items():\n",
        "        setattr(self, parameter, value)\n",
        "    return self\n",
        "      \n",
        "  def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "        self._classes = np.unique(y)\n",
        "\n",
        "  def predict(self, X):\n",
        "        y_pred = [self._predict(x) for x in X]\n",
        "        return np.array(y_pred)\n",
        "  \n",
        "  def _predict(self, x):\n",
        "        posteriors = []\n",
        "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
        "        k_idx = np.argsort(distances)[:self.k]\n",
        "        k_neighbor_labels = [self.y_train[i] for i in k_idx]\n",
        "        for idx, c in enumerate(self._classes):\n",
        "            kj = k_neighbor_labels.count(idx)\n",
        "            posterior = kj/self.k\n",
        "            posteriors.append(posterior)\n",
        "        return np.argmax(posteriors)\n",
        "\n",
        "  def predictProb(self, X):\n",
        "        prob = [self._predictProb(x) for x in X]\n",
        "        return np.array(prob)\n",
        "  \n",
        "  def _predictProb(self, x):\n",
        "        posteriors = []\n",
        "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
        "        k_idx = np.argsort(distances)[:self.k]\n",
        "        k_neighbor_labels = [self.y_train[i] for i in k_idx]\n",
        "        for idx, c in enumerate(self._classes):\n",
        "            kj = k_neighbor_labels.count(idx)\n",
        "            posterior = kj/self.k\n",
        "            posteriors.append(posterior)\n",
        "        return posteriors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mLOzAaUZjjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictSoma(pred, X_test1, y_test):\n",
        "    soma = []\n",
        "    p = []\n",
        "    sum = 0\n",
        "    y_pred = []\n",
        "    _classes = np.unique(y)\n",
        "    priors = []\n",
        "    for x in range (len(X_test1)):\n",
        "      for idx, c in enumerate(_classes):\n",
        "          nj = np.count_nonzero(y_test == idx)\n",
        "          priori = nj/len(y_test)\n",
        "          priors.append(priori)\n",
        "          for clf in range(3):\n",
        "            sum = sum + pred[x][clf][idx]\n",
        "          soma.append(sum)\n",
        "          sum = 0\n",
        "          aux = ((1-3)*priors[idx] + soma[idx])\n",
        "          p.append(aux)\n",
        "      soma=[]\n",
        "      y_pred.append(np.argmax(p))\n",
        "      p=[]\n",
        "    return np.array(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBXE6MGFuxbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "view1 = pd.read_csv('https://raw.githubusercontent.com/jsaj/MachineLearning/master/mfeat-fac.csv', header = None, delim_whitespace=True)\n",
        "view2 = pd.read_csv('https://raw.githubusercontent.com/jsaj/MachineLearning/master/mfeat-fou.csv', header = None, delim_whitespace=True)\n",
        "view3 = pd.read_csv('https://raw.githubusercontent.com/jsaj/MachineLearning/master/mfeat-kar.csv', header = None, delim_whitespace=True)\n",
        "\n",
        "target = pd.read_csv('https://raw.githubusercontent.com/jsaj/MachineLearning/master/cluster_membership_tres_m.csv', header = None, delim_whitespace=True)\n",
        "\n",
        "view1 = preprocessing.normalize(view1, 'max')\n",
        "view2 = preprocessing.normalize(view2, 'max')\n",
        "view3 = preprocessing.normalize(view3, 'max')\n",
        "\n",
        "X1 = view1\n",
        "X2 = view2\n",
        "X3 = view3\n",
        "\n",
        "y = np.array(target.values).T[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwUUhPcJ0CaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=30)\n",
        "scores = []\n",
        "\n",
        "for train_index, test_index in rskf.split(X1,y):\n",
        "    X_train1, X_test1 = X1[train_index], X1[test_index]\n",
        "    X_train2, X_test2 = X2[train_index], X2[test_index]\n",
        "    X_train3, X_test3 = X3[train_index], X3[test_index]\n",
        "    \n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    X_val1,X_valt1,y_val1,y_valt1 = train_test_split(X_train1, y_train,train_size=0.20)\n",
        "    X_val2,X_valt2,y_val2,y_valt2 = train_test_split(X_train2, y_train,train_size=0.20)\n",
        "    X_val3,X_valt3,y_val3,y_valt3 = train_test_split(X_train3, y_train,train_size=0.20)\n",
        "\n",
        "    Xval = [X_val1, X_val2, X_val3]\n",
        "    yval = [y_val1, y_val2, y_val3]\n",
        "\n",
        "    neighbors = list(range(1, 20, 2))\n",
        "    K = []\n",
        "    for i in range (len(Xval)): \n",
        "      cv_scores = []\n",
        "      for k in neighbors:\n",
        "        bnn = BayesNN(k=k)\n",
        "        scor = cross_val_score(bnn, Xval[i], yval[i], cv=10, scoring='accuracy')\n",
        "        cv_scores.append(scor.mean())\n",
        "      mse = [1 - x for x in cv_scores]\n",
        "      # determina o melhor k\n",
        "      optimal_k = neighbors[mse.index(min(mse))]\n",
        "      K.append(optimal_k)\n",
        "        \n",
        "    model1 = BayesNN(K[0])\n",
        "    model2 = BayesNN(K[1])\n",
        "    model3 = BayesNN(K[2])\n",
        "\n",
        "    model1.fit (X_train1, y_train) \n",
        "    model2.fit (X_train2, y_train) \n",
        "    model3.fit (X_train3, y_train) \n",
        "\n",
        "    pred1 = model1.predictProb(X_test1) \n",
        "    pred2 = model2.predictProb(X_test2) \n",
        "    pred3 = model3.predictProb(X_test3)\n",
        "    pred = [[pred1[x], pred2[x], pred3[x]]  for x in range (len(X_test1))]\n",
        "\n",
        "    y_pred = predictSoma(pred, X_test1, y_test)\n",
        "    score = accuracy_score(y_test, y_pred)\n",
        "    scores.append(score)\n",
        "    print(len(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pouW4O88zlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT0MRwGIWtMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confidence = 0.95\n",
        "\n",
        "n = len(scores)\n",
        "m = mean(scores)\n",
        "std_ = np.std(scores)\n",
        "std_err = sem(scores)\n",
        "h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
        "\n",
        "\n",
        "print(\"Média\", m)\n",
        "print(\"Desvio padrão \", std_)\n",
        "print(\"Erro Padrão\", std_err)\n",
        "start = m - h\n",
        "end = m + h\n",
        "print(\"Intervalo de confiança\", start, end)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}